{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70352e3c-2713-4f7f-889e-a18c1bf280e6",
   "metadata": {},
   "source": [
    "# Finite Hypothesis Classes\n",
    "\n",
    "In this homework, you will explore how to implement and use finite hypothesis classes.\n",
    "You will use the famous MNIST dataset for handwritten digit recognition.\n",
    "\n",
    "<img src=\"img/mnist.png\" />\n",
    "\n",
    "With the simple finite hypothesis classes we've studied so far, you should be able to get about 90% accuracy on this problem.\n",
    "By the end of the semester, you'll be able to get state-of-the-art (SOTA) accuracy of >99%.\n",
    "\n",
    "**Instructions:**\n",
    "You should read through the code starting with Part 1 below.\n",
    "The comments contain detailed descriptions of what the code is doing.\n",
    "There are three FIXME annotations in the comments (in parts 1, 3, and 4).\n",
    "You should complete the tasks specified by those FIXME annotations by modifying the jupyter notebook directly.\n",
    "Once you've completed all the tasks,\n",
    "create a new github repo and upload this notebook to github.\n",
    "Submit the assignment by copying the link to your repo in sakai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b33e5-37f7-4023-872b-b06e97dfbf23",
   "metadata": {},
   "source": [
    "## Part 0: Background\n",
    "\n",
    "This section contains imports and helper functions used by the code in parts 1+.\n",
    "It is safe to skip reading the code in this section for now,\n",
    "but you will likely have to refer to it later to see how to use the helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75b19d3c-f3d6-445a-b7c7-00febf80477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import time\n",
    "\n",
    "# make numpy random numbers deterministic\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# enable plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edf84e74-8bbc-432f-8b3a-282623776629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(a):\n",
    "    '''\n",
    "    Convert a boolean value into +/- 1.\n",
    "\n",
    "    >>> sign(12.5)\n",
    "    1\n",
    "    >>> sign(-12.5)\n",
    "    -1\n",
    "    '''\n",
    "    if a > 0:\n",
    "        return 1\n",
    "    if a <= 0:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def set_exp(xs, p):\n",
    "    '''\n",
    "    Compute the \"set exponential\" function.\n",
    "\n",
    "    For efficiency, this function is a generator.\n",
    "    This means that large sets will never be explicitly stored,\n",
    "    and this function will always use O(1) memory.\n",
    "\n",
    "    The doctests below first convert the generator into a list for visualization.\n",
    "\n",
    "    >>> list(set_exp([-1, +1], 0))\n",
    "    []\n",
    "    >>> list(set_exp([-1, +1], 1))\n",
    "    [[-1], [1]]\n",
    "    >>> list(set_exp([-1, +1], 2))\n",
    "    [[-1, -1], [1, -1], [-1, 1], [1, 1]]\n",
    "    >>> list(set_exp([-1, +1], 3))\n",
    "    [[-1, -1, -1], [1, -1, -1], [-1, 1, -1], [1, 1, -1], [-1, -1, 1], [1, -1, 1], [-1, 1, 1], [1, 1, 1]]\n",
    "\n",
    "    Observe that the length grows exponentially with the power.\n",
    "\n",
    "    >>> len(list(set_exp([-1, +1], 4)))\n",
    "    16\n",
    "    >>> len(list(set_exp([-1, +1], 5)))\n",
    "    32\n",
    "    >>> len(list(set_exp([-1, +1], 6)))\n",
    "    64\n",
    "    >>> len(list(set_exp([-1, +1], 7)))\n",
    "    128\n",
    "    >>> len(list(set_exp([-1, +1], 8)))\n",
    "    256\n",
    "    '''\n",
    "    assert(len(xs) > 0)\n",
    "    assert(p >= 0)\n",
    "    assert(type(p) == int)\n",
    "    if p == 1:\n",
    "        for x in xs:\n",
    "            yield [x]\n",
    "    elif p > 1:\n",
    "        for x in xs:\n",
    "            for ys in set_exp(xs, p - 1):\n",
    "                yield ys + [x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e448f-31d7-4870-8904-5268472c6739",
   "metadata": {},
   "source": [
    "## Part 1: Hypothesis Classes\n",
    "\n",
    "This section explores how to translate the mathematical definitions of the finite hypothesis classes into python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8de7c07-8eb3-44b4-9316-7566fed7ba26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ypred=1\n",
      "ypred=-1\n"
     ]
    }
   ],
   "source": [
    "# The H_binary hypothesis class is easy to represent in code as a list of anonymous functions\n",
    "H_binary = [lambda x: 1, lambda x: -1]\n",
    "\n",
    "# The code below shows how to use one of these functions.\n",
    "# First we define an example datapoint.\n",
    "# Then we apply every hypothesis h in the hypothesis class to the sample.\n",
    "x = np.array([12.5, -12.5])\n",
    "for h in H_binary:\n",
    "    ypred = h(x)\n",
    "    print(f'ypred={ypred}')\n",
    "    \n",
    "# You should ensure that you understand the output of this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "987ac5a7-5c3f-4a75-be44-12b4310ca51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ypred=-1\n",
      "ypred=-1\n"
     ]
    }
   ],
   "source": [
    "# H_axis is harder to represent in code;\n",
    "# the \"obvious\" thing to do is something like the following two lines of code\n",
    "d = 2\n",
    "H_axis = [lambda x: sign(x[i]) for i in range(d)]\n",
    "\n",
    "# unfortunately, there is a serious bug in this code\n",
    "# to illustrate the bug, let's try applying every hypothesis to the same data point as above\n",
    "x = np.array([12.5, -12.5])\n",
    "for h in H_axis:\n",
    "    ypred = h(x)\n",
    "    print(f'ypred={ypred}')\n",
    "\n",
    "# Notice that the output is the same for both functions,\n",
    "# but the output *should* be different.\n",
    "# That's because on this particular dataset, sign(x[0]) should be +1 and sign(x[1]) should be -1.\n",
    "# the problem is that we're getting -1 twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cc4b663-98af-4f57-a1db-9a947e962ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ypred=1\n",
      "ypred=-1\n"
     ]
    }
   ],
   "source": [
    "# the problem observed above is related to something called a closure in python\n",
    "# closures are a fundamental part of modern programming,\n",
    "# and it is extremely important that you understand how they work.\n",
    "# it is common in technical interviews for SWE positions to be asked syntax-related questions about closures\n",
    "\n",
    "# for the specific case of using a lambda inside of a list comprehension,\n",
    "# you can find a detailed explanation of what is happening on stackoverflow at\n",
    "# <https://stackoverflow.com/questions/28268439/python-list-comprehension-with-lambdas>\n",
    "\n",
    "# to fix our problem, we can use a default argument to change the scope of the variable i\n",
    "# in general, when translating set builder notation into python,\n",
    "# it is necessary to do this step for all variables that you are \"looping over\"\n",
    "H_axis = [lambda x, i=i: sign(x[i]) for i in range(d)]\n",
    "\n",
    "# now observe that we get the correct output\n",
    "x = np.array([12.5, -12.5])\n",
    "for h in H_axis:\n",
    "    ypred = h(x)\n",
    "    print(f'ypred={ypred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7a19dae-4953-4b87-9ef1-bc787d288b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_binary\n",
      "ypred=1\n",
      "ypred=-1\n",
      "H_axis\n",
      "ypred=1\n",
      "ypred=-1\n",
      "ypred=1\n",
      "ypred=-1\n"
     ]
    }
   ],
   "source": [
    "# there's one last minor problem with our definitions of the H_binary and H_axis hypothesis classes above:\n",
    "# we've hard-coded the number of dimensions.\n",
    "# we can make our hypothesis classes more generic by wrapping them in another lambda to specify the dimension\n",
    "\n",
    "H_binary = lambda d: [lambda x: 1, lambda x: -1]\n",
    "H_axis = lambda d: [lambda x, i=i: sign(x[i]) for i in range(d)]\n",
    "\n",
    "# now to use the class, we need to specify the number of dimensions;\n",
    "# here's an example in 4 dimensions\n",
    "x = np.array([12.5, -12.5, 1.2, -1.2])\n",
    "print('H_binary')\n",
    "for h in H_binary(4):\n",
    "    ypred = h(x)\n",
    "    print(f'ypred={ypred}')\n",
    "\n",
    "print('H_axis')\n",
    "for h in H_axis(4):\n",
    "    ypred = h(x)\n",
    "    print(f'ypred={ypred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b44d063c-4ac7-4b1e-9900-fc25f11f6407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# notice that the size of H_binary doesn't change based on the number of dimensions,\n",
    "# but that the size of H_axis does\n",
    "print(len(H_binary(2)))\n",
    "print(len(H_axis(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60e44e40-0665-4b97-b150-7eab0be5e993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  d     len(H_binary(d))      len(H_axis(d))     len(H_axis2(d))     len(H_multiaxis2(d))     len(H_multiaxis3(d))\n",
      "  1                    2                   1                   2                        2                        3\n",
      "  2                    2                   2                   4                        4                        9\n",
      "  3                    2                   3                   6                        8                       27\n",
      "  4                    2                   4                   8                       16                       81\n",
      "  5                    2                   5                  10                       32                      243\n",
      "  6                    2                   6                  12                       64                      729\n",
      "  7                    2                   7                  14                      128                     2187\n",
      "  8                    2                   8                  16                      256                     6561\n",
      "  9                    2                   9                  18                      512                    19683\n",
      " 10                    2                  10                  20                     1024                    59049\n"
     ]
    }
   ],
   "source": [
    "# FIXME:\n",
    "# define the hypothesis classes below\n",
    "# HINT:\n",
    "# the multiaxis* hypothesis classes should loop over a sigma vector created from the set_exp function defined above\n",
    "H_binary = lambda d: [lambda x: +1, lambda x: -1]\n",
    "H_axis = lambda d: [lambda x, i=i: sign(x[i]) for i in range(d)]\n",
    "H_axis2 = lambda d: [lambda x, i = i, sigma=sigma: sigma*sign(x[i]) for i in range(d) for sigma in {-1, 1}]\n",
    "H_multiaxis2 = lambda d: [lambda x, sigma = sigma: sign(sum(sigma*x[i]) for i in range(d)) for sigma in set_exp([-1, 1], d)]\n",
    "H_multiaxis3 = lambda d: [lambda x, sigma = sigma: sign(sum(sigma*x[i]) for i in range(d)) for sigma in set_exp([-1, 0, 1], d)]\n",
    "\n",
    "# the following code prints a nice table showing the size of the finite hypothesis classes in different dimensions\n",
    "# you will know your implementations above are correct if the sizes match the formulas we derived in the notes \n",
    "print(f'  d {\"len(H_binary(d))\":>20}{\"len(H_axis(d))\":>20}{\"len(H_axis2(d))\":>20}{\"len(H_multiaxis2(d))\":>25}{\"len(H_multiaxis3(d))\":>25}')\n",
    "for d in range(1, 11):\n",
    "    print(f' {d:2} {len(H_binary(d)):20d}{len(H_axis(d)):20d}{len(H_axis2(d)):20d}{len(H_multiaxis2(d)):25d}{len(H_multiaxis3(d)):25d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d195ae-06fb-4703-adaf-dbf27e019c19",
   "metadata": {},
   "source": [
    "## Part 2: Loading the MNIST Data\n",
    "\n",
    "This section loads the dataset.\n",
    "There are no FIXME annotations in this section.\n",
    "It would still be useful to skim this section, however, because the subsequent sections rely on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "982aca51-8b83-4a41-bcbe-02fe09d9fca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=(14867, 784)\n",
      "y.shape=(14867,)\n"
     ]
    }
   ],
   "source": [
    "# scikit learn has built-in functions for loading lots of standard datasets\n",
    "# the MNIST dataset is small by machine learning standards,\n",
    "# but it still takes 10-20 seconds to load on my machine\n",
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "# the standard MNIST problem has 10 classes, one for each numeric digit\n",
    "# we've only studied binary classification in class so far,\n",
    "# so we'll convert MNIST into a binary problem\n",
    "# the idea is that we will label all \"1\"s as +1, all \"2\"s as -1, and delete all othe other digits\n",
    "label_positive = '1'\n",
    "label_negative = '2'\n",
    "dataset_mask = np.logical_or(y == label_positive, y == label_negative)\n",
    "X = X[dataset_mask]\n",
    "y = y[dataset_mask]\n",
    "y[y == label_positive] = +1\n",
    "y[y == label_negative] = -1\n",
    "y = y.astype(np.int64)\n",
    "\n",
    "# for debugging purposes, I always print the shape of my important tensors\n",
    "print(f\"X.shape={X.shape}\") # shape = N x d\n",
    "print(f\"y.shape={y.shape}\") # shape = N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4612a35d-05d4-4f67-9491-e88c3fc21f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0, y[i]=1, x[i]=\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=1, y[i]=-1, x[i]=\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=2, y[i]=1, x[i]=\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEO0lEQVR4nO2bz0/iTByHn1JYxSJIYV1W0ET8EY3xoCZ71D9g/1Cv3j152cPevKwHo4ho/AUEaoVCKX0PG1kdkbzvwRny7jxJE9I58MnDzHxnptQIwxDNHyKqA4wbWoiAFiKghQhoIQLRUY2GYfxvS1AYhsaw+7qHCGghAlqIgBYioIUIaCECI8vuR5JKpUin0ySTSaanp/F9n263y/39PbVajV6vRxAE0nMpE7K5ucn379/Z2tri27dvPDw8UK1W2d/f5+DggEajgeu60nNJF2KaJrFYjGw2S7FYZG5ujnQ6DUAsFsO2bRKJBK1WS3Y0QIGQeDyObdusra2xt7fH1NQUYRiSTCZJJBIUCgUKhQKtVot6vS47nnwh/X4f3/fxPI/Hx0ei0ShhGGIYBpFIhEgkgmmaGMbQlfWHI73K+L6P4zhcX19zcnLC/f297AgjkS6k3+/T6/XodDo8Pj7S6XRkRxiJ9CETBAFBEOA4DtVqVdnk+R7ShTzPEfF4nFQqxcTEhOwII5EuJBqNEo/HyWazLCwsMDMzIzvCSKTPIZFIhGg0yuTkJIlE4k0PmZqawrZtUqkUlmURjcr9zZQI+fTpE5ZlkclkiMfjr9pt26ZYLPL161cymQyTk5NS80kfMr1ej1arxd3dHaenpywuLg5WqgD5fJ6dnR1c1+Xp6Qnf96Uu4aUL6Xa7dLtdSqUSP378wDRNlpeXB+3r6+usra0RBAG9Xo9Go8HNzY20fMq2/7e3t/z8+ZNKpfKmTdUqFRTudi8uLri4uGBra0tVhKEoE/KSYT3ir9nLDEPlEBEZCyHjhPIhE4Yh/X5/8PnlfRXoHiKghQhoIQJaiIByIc9nqYZhvLqy2SxLS0skk0mpeZQLeY+ZmRkKhQKJRELq9yovuzC8xObzeSzLolgsksvlaDabtNvtD8+iXMjLdchLbNsmnU6Ty+WwbRvP86QIUT5kyuUyR0dHlMvlN22GYbCyssLu7i65XE5KHuVCarUav379olqtDm3/8uULq6urpFIpKXmUC3Fdl9vbWyUPtoehXIjnedTr9VfPZ55LL/w5lJa1I1Y+qZ6fn9NsNpmfn2d7e5vp6WksywJ+i9nY2CCfz3N8fEypVKLZbOJ53oflUS6k0WgMzk1d12ViYmIgBGB2dpZsNsvnz5+xLIunp6cPzaN8yDzjOA6VSgXHcV7dD8NwcMlgbIS0223q9Tqe572SIFMGjJGQs7MzDg8PKZVKSnOMjZBGo0G5XKbZbNLv9/WJmeM4XF5eUqlUuLq6UrYuUV5lnul0OriuS7Va5fr6Gt/38X0f+P0nm3a7TRAEH95zjFFfIPP1ENM0MU2T2dlZMpkMsVhs8OQ/DEMqlQq1Wg3f94duBv8r770eMjZCZKPfl/mXaCECWoiAFiKghQhoIQIjy+7fiO4hAlqIgBYioIUIaCECWojAPw/np/YLuq1jAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=3, y[i]=1, x[i]=\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAADp0lEQVR4nO2bzU7jPBSG36RO6gQCSdt0VXUBG1T2bEBiwYJr4Eq4BG6GC2GHkLpCSCC1CAIlpD8hIc3PLFAzg2cGfZuxrQ8/UlUpXfjVoxMfx260qqqg+IkuOoBsKCEMSgiDEsKghDCQr37UNO1/24KqqtL+dF1VCIMSwqCEMCghDEoIgxLCoIQwKCEMXy7M/jWapqHZbIJSilarBc/zcH9/j8fHR2GZhFWIrutoNBrodrvY3d3FyckJzs7OcHh4KCrSRy5hA+s6DMNAv9/H/v4+dnZ24Ps+HMeBaZpoNBpCcgm7ZQghsG0bR0dHOD09RZqmSJIE7XYbnudhPp/j7e2Nfy7uI/6CpmkghIBSWl+zLAuUUiEyAIm6DKUUruvWn2azKSSH0Ar5FU3T6u/VRwTSVIgsSCdk1Y5VhQCoqqpux6LarjRCVgdma2tr8H1f2KQqjZAVruui3+9jc3NTyPhChZRliTzPkWUZiqIA8LEO2djY+H4VUlUVyrJElmVIkgR5ngMAbNtGt9v9tFjjiTAheZ4jTVNEUYTxeIzZbCYqyieECSmKAmmaYjKZ4Pb2FlEUiYryCeGTqmx/xxAuRDakE2IYBizLgmEYQsaXTohpmrBtG4SIee6UTojv+xgMBmi1WkLGl+bxf0Wn04HjOHBdV8j4wivk9fUVNzc3CMNQdBQAEgiZTqcYjUaYTqeiowCQQEiapgjDEGmaAvi5H7K+vo5Wq8X9mUa4kOVyicVigSzLAHxsIeq6DkopHMfh3n6FC6mqCkVRoCzL+pqmaWg0GiCEQNf5RhQupCxLFEXx2xJe1/XvKSQIAlxeXuL6+hoPDw9IkgSGYWAwGOD4+Bi9Xo9rHuFC5vM5xuMxnp6eEIYhsiyrz3y3t7e575xJszALggDD4RBlWcK2bVxcXOD8/Bx3d3dcc0gjJI5jBEGAXq+HPM8xHo9xdXVV76TxQvgt8ydWnSfP80/dhwdSClmtRXRd535gJZ0Q0zRhWRa2trawt7eHbrfLdXxphKxO7AghIITAcRx0Oh3uu+/STKr9fh8HBwfwfR/L5RIvLy8YjUZYLBZcc0hTIZRSeJ4H0zSRZRnSNEUcx9y7jDQV8vz8jOFwiHa7Ddd1EUUR3t/f6xM9XkgjZLUvkiQJ4jjGbDYT0na1r85FeL5A5HkePM+rJ9XJZIIoiv6ZlL+9QCSNEN6oN6r+I0oIgxLCoIQwfDmpfkdUhTAoIQxKCIMSwqCEMCghDD8AcjJC/ZUA5yUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=4, y[i]=1, x[i]=\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAADRElEQVR4nO2bzU7qWhiGn1KQ0kBNFQiKicHEgSNCotfitZl4J96FAx1oNFbEBP9KUxYChZ7BPrDdK3uTM9l8zXE9SSftYL158q2uv9ZK0xTDT3LSAbKGEaJhhGgYIRpGiEZ+1UPLsv63Q1Captbv7psK0TBCNIwQDSNEwwjRMEI0jBANI0Rj5cTsb7K9vU2j0aBUKuG6Lt1ul6enJ5IkYTabScWSE3J8fMzp6SkHBwccHh5ydnbG+fk5URQRx7FUrPV3GcuysG2bSqVCs9mkXq/j+z7VapV6vY7ruuuO9AtrrxDbtikUCtRqNY6OjqhUKjiOw97eHp1OhyRJ6Pf76461ZO0VMp/Pmc1mTKdTlFIkSQJAoVDAdV02NjbWHekXRIRMJhMGgwHPz89EUQSA4zh4nvf9hCz4+Pjg5uaGt7c3AIrFIp7nUSwWpSIBgkKCIODi4oLb21sAKpUKu7u7lMtlqUiAoBClFP1+fznE+r5Pq9WiVqtRKpXI52VmBGJCBoMBd3d3vL+/A9BsNjk5OaHVarG5uSn2LhET8vWAzLIscrkc+Xyera0t9vf38TxPJFdm1jK5XA7btmk2m7TbbarVqkwOkVZXsJjJ5nIy0cTWMl/52n0WXUdKSOYqRBojRMMI0TBCNDIhxLIsLOu3J4trJxNCsoQRopG5eciqe+sgcxUSRRG9Xo/hcCjSfuaEKKV4eXlhNBqJtJ85IcPhkNfXVyNkwefnJ1EUMZlMRNrPnBBpjBCNzAmxbdss/79i9kM0Go0GnU7ne24hpmm6vBZ4nkej0RA7nxETMh6PCcOQfr9Pt9tdHmlKIyZkNpsxHo9RShFFEePx+Eegf3ffpRATMp/PSZKEyWTCdDpdfjW0s7NDu92mXq+L5BJ/hyy+BlgIcV2XarWK4zgimcRHmTAMub+/JwxD4Md3Io7jiHUbcSGL1W0cxyRJsryk9kPEN4iur69RSqGUolwuc3l5ydXVFb1eTySPeIUMBgOCIODh4YEgCAiCgMfHR7Fh2FpVmuv4gci2bWzbxvd9fN9HKcVoNCKO47+6J/KnH4jEhUhh/qj6jxghGkaIhhGisfKl+h0xFaJhhGgYIRpGiIYRomGEaPwDvI06guM3k3YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# it's always a good idea to visualize your datapoints after loading them\n",
    "# this lets us sanity check that our labels are in fact correct\n",
    "for i in range(5):\n",
    "    print(f\"i={i}, y[i]={y[i]}, x[i]=\")\n",
    "    image = X[i].reshape([28,28])\n",
    "    fig = plt.figure(figsize=(1,1))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2be2af7-b4bc-4408-b5bc-4779cd8f4e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain.shape=(1000, 784)\n",
      "ytrain.shape=(1000,)\n",
      "Xtest.shape=(10000, 784)\n",
      "ytest.shape=(10000,)\n"
     ]
    }
   ],
   "source": [
    "# we now split the dataset into a training a testing datasets\n",
    "# we will use a relatively small N value (just to make your future experiments faster)\n",
    "# we also have a large Ntest value, so we can be fairly confident that |Etest - Eout| is small\n",
    "N = 1000\n",
    "Ntest = 10000\n",
    "Xtrain = X[:N]\n",
    "ytrain = y[:N]\n",
    "Xtest = X[N:N+Ntest]\n",
    "ytest = y[N:N+Ntest]\n",
    "print(f\"Xtrain.shape={Xtrain.shape}\")\n",
    "print(f\"ytrain.shape={ytrain.shape}\")\n",
    "print(f\"Xtest.shape={Xtest.shape}\")\n",
    "print(f\"ytest.shape={ytest.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc413fc-ad13-43dc-883b-6378b3e7f7e6",
   "metadata": {},
   "source": [
    "## Part 3: Model Training\n",
    "\n",
    "This section introduces how to implmement and use scikit learn models.\n",
    "In general, you won't have to implement the more \"interesting\" models because they are already implemented.\n",
    "But you will have to implement the TEA model.\n",
    "The main purpose of this task is to just get you familiar with how scikit learn is structured so that you will be able to effectively use it later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9d0faad-c764-47a6-bb6b-895d39920f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime=0.8 seconds\n",
      "Ein=0.1540\n",
      "Etest=0.1504\n",
      "generalization error=0.0036\n"
     ]
    }
   ],
   "source": [
    "# in scikit learn, all learning models are implemented as a class\n",
    "# these classes are called \"estimators\",\n",
    "# and they follow the interface specified in <https://scikit-learn.org/dev/developers/develop.html>\n",
    "# in particular, all estimators will need at least three methods:\n",
    "# (1) __init__ specifies the hyperparameters to the model\n",
    "# (2) fit takes the training dataset as input and computes the hypothesis in the hypothesis class\n",
    "# (3) predict applies the hypothesis to an input datapoint or dataset\n",
    "\n",
    "class TEA:\n",
    "    def __init__(self, H):\n",
    "        self.H = H\n",
    "        self.g = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        # FIXME:\n",
    "        # implement the fit method following the pseudocode for TEA from the notes;\n",
    "        # your implementation should store the final hypothesis in the self.g variable\n",
    "        # HINT:\n",
    "        # everything so far is deterministic, so your code will be correct if it gets the exact same results as mine\n",
    "        # my results are\n",
    "        # for H_binary: Ein=0.4710\n",
    "        # for H_axis: 0.1540\n",
    "        # for H_axis2: 0.1540\n",
    "        # you won't be able to use the H_multiaxis2 or H_multiaxis3 hypothesis classes because of the exponential runtimes\n",
    "        d = X.shape[1]\n",
    "        g_score = float('-inf')\n",
    "\n",
    "        for h in self.H(d):\n",
    "            h_pred = np.array([h(x) for x in X])\n",
    "            h_score = sklearn.metrics.accuracy_score(h_pred, Y)\n",
    "            if h_score > g_score:\n",
    "                self.g = h\n",
    "                g_score = h_score\n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        assert(self.g is not None)\n",
    "        if len(X.shape) == 1:\n",
    "            return self.g(X)\n",
    "        else:\n",
    "            return np.apply_along_axis(self.g, 1, X)\n",
    "\n",
    "# we now train the model by passing the training data to the .fit method\n",
    "model = TEA(H_axis2) # replace H_axis with other hypothesis classes\n",
    "time_start = time.time()\n",
    "model.fit(Xtrain, ytrain)\n",
    "time_end = time.time()\n",
    "runtime = time_end - time_start\n",
    "print(f\"runtime={runtime:0.1f} seconds\")\n",
    "\n",
    "# report the relavent metrics\n",
    "# scikit learn does not have an error metric built in, \n",
    "# but we can compute it as 1 - accuracy\n",
    "ytrain_pred = model.predict(Xtrain)\n",
    "Ein = 1 - sklearn.metrics.accuracy_score(ytrain_pred, ytrain)\n",
    "print(f\"Ein={Ein:0.4f}\")\n",
    "ytest_pred = model.predict(Xtest)\n",
    "Etest = 1 - sklearn.metrics.accuracy_score(ytest_pred, ytest)\n",
    "print(f\"Etest={Etest:0.4f}\")\n",
    "print(f'generalization error={abs(Etest - Ein):0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24c2cd-7e25-43a7-824b-1fb5bef8fde5",
   "metadata": {},
   "source": [
    "## Part 4: Data preprocessing with random projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebc3a5bd-0688-41cf-91fe-4376a892e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afull.shape=(784, 784)\n"
     ]
    }
   ],
   "source": [
    "# recall that one of the most important parts of this class is learning how to effectively preprocess data\n",
    "# in the real world, you will never have to implement your own machine learning algorithms\n",
    "# existing implementations in libraries like scikit learn are highly optimized,\n",
    "# and there's no need to reinvent the wheel.\n",
    "# but you will have to preprocess data\n",
    "\n",
    "# one of the most important forms of preprocessing is the random projection\n",
    "# recall that projecting the data onto a smaller dimension (dprime) will cause:\n",
    "# (1) the runtime for TEA to go down,\n",
    "# (2) the generalization error |Ein - Eout| to go down,\n",
    "# (3) the training error Ein to go up\n",
    "# every application will have different demands on these quantities,\n",
    "# and so you will have to choose an appropriate dimension dprime for your application\n",
    "\n",
    "# to project the data, we need to generate a random d x dprime matrix\n",
    "# we use two tricks to generate the random matrix deterministically:\n",
    "# first, we set the seed; this ensures that every run of this cell will create the same matrix\n",
    "# (although the same seed will result in different matrices on different computers)\n",
    "# second, we create a full matrix and then slice it to the appropriate size\n",
    "# this ensures that the value of dprime does not affect the contents of A\n",
    "np.random.seed(0)\n",
    "d = X.shape[1]\n",
    "Afull = np.random.uniform(low=-1, high=1, size=(d, d))\n",
    "print(f'Afull.shape={Afull.shape}') # shape = d x d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8174cc89-cfd3-4374-90ab-83823dca5c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xprime.shape=(14867, 784)\n",
      "i=0, y[i]=1, x[i]=\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAAAOCAYAAABpXl0fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAQ0lEQVR4nO3SwQkAIBDAMHX/nc8lBKEkE/TRPTMLSs7vAHjN1OSYmhxTk2NqckxNjqnJMTU5pibH1OSYmhxTk2Nqci7O1gMZcm8ofQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=1, y[i]=-1, x[i]=\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAAAOCAYAAABpXl0fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAQ0lEQVR4nO3SwQkAIBDAMHX/nc8lBKEkE/TRPTMLSs7vAHjN1OSYmhxTk2NqckxNjqnJMTU5pibH1OSYmhxTk2Nqci7O1gMZcm8ofQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=2, y[i]=1, x[i]=\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAAAOCAYAAABpXl0fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAQ0lEQVR4nO3SwQkAIBDAMHX/nc8lBKEkE/TRPTMLSs7vAHjN1OSYmhxTk2NqckxNjqnJMTU5pibH1OSYmhxTk2Nqci7O1gMZcm8ofQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=3, y[i]=1, x[i]=\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAAAOCAYAAABpXl0fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAQ0lEQVR4nO3SwQkAIBDAMHX/nc8lBKEkE/TRPTMLSs7vAHjN1OSYmhxTk2NqckxNjqnJMTU5pibH1OSYmhxTk2Nqci7O1gMZcm8ofQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=4, y[i]=1, x[i]=\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAAAOCAYAAABpXl0fAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAQ0lEQVR4nO3SwQkAIBDAMHX/nc8lBKEkE/TRPTMLSs7vAHjN1OSYmhxTk2NqckxNjqnJMTU5pibH1OSYmhxTk2Nqci7O1gMZcm8ofQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the code below plots the data points after they have been projected down into a very small dprime\n",
    "dprime = 784\n",
    "A = Afull[:, :dprime]\n",
    "Xprime = X @ A\n",
    "print(f\"Xprime.shape={Xprime.shape}\")\n",
    "for i in range(5):\n",
    "    print(f\"i={i}, y[i]={y[i]}, x[i]=\")\n",
    "    image = Xprime[i].reshape([1, dprime])\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c32f1c98-b2d8-41d1-a1da-48717613855d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime=0.5 seconds\n",
      "Ein=0.1680\n",
      "Etest=0.1744\n",
      "generalization error=0.0064\n"
     ]
    }
   ],
   "source": [
    "# the images above are no longer human interpretable;\n",
    "# remarkably, we can still learn an effective hypothesis on these newly transformed data points\n",
    "# with dprime=5, my results on H_axis2 are nearly as good as they were for the full dataset\n",
    "# on this smaller dataset size, we can actually now try the H_multiaxis* hypothesis classes as well\n",
    "\n",
    "model = TEA(H_axis)\n",
    "time_start = time.time()\n",
    "model.fit(Xtrain @ A, ytrain)\n",
    "time_end = time.time()\n",
    "runtime = time_end - time_start\n",
    "print(f\"runtime={runtime:0.1f} seconds\")\n",
    "\n",
    "ytrain_pred = model.predict(Xtrain @ A)\n",
    "Ein = 1 - sklearn.metrics.accuracy_score(ytrain_pred, ytrain)\n",
    "print(f\"Ein={Ein:0.4f}\")\n",
    "\n",
    "ytest_pred = model.predict(Xtest @ A)\n",
    "Etest = 1 - sklearn.metrics.accuracy_score(ytest, ytest_pred)\n",
    "print(f\"Etest={Etest:0.4f}\")\n",
    "\n",
    "print(f'generalization error={abs(Etest - Ein):0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b311faaf-3e3e-405a-bc2b-37da77888d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe best combination of hyperparameters for this problem is the H_axis hypothesis class and dprime=784, resulting in an Etest of .1744.\\nIt appears that although the Ein for H_axis2 is lower, it actually results in a higher Etest as it may be overfitting the data.\\nH_axis has a smaller hypothesis class than H_axis2, and therefore is less likely to overfit the data.\\nSetting dprime = 784 should result in the best Etest because it is the same dimension as the original dataset, and therefore does not lose any information.\\nAs we have learned, smaller dprimes will result in a lower generalization error, but a higher training error since reducing dprime will reduce M, the number of hypothesis classes. \\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIXME:\n",
    "# your final task for this homework is to find the best possible combination of hyperparameters for this problem;\n",
    "# that is, find the best combination of hypothesis class and dprime that minimizes Etest\n",
    "# you don't have to consider hypothesis classes that take a very long amount of time to complete\n",
    "\n",
    "# modify the code block above to contain your hyperparameters\n",
    "# write a short description here about why you chose those hyperparameters and how they connect to the theory\n",
    "\"\"\"\n",
    "The best combination of hyperparameters for this problem is the H_axis hypothesis class and dprime=784, resulting in an Etest of .1744.\n",
    "It appears that although the Ein for H_axis2 is lower, it actually results in a higher Etest as it may be overfitting the data.\n",
    "H_axis has a smaller hypothesis class than H_axis2, and therefore is less likely to overfit the data.\n",
    "Setting dprime = 784 should result in the best Etest because it is the same dimension as the original dataset, and therefore does not lose any information.\n",
    "As we have learned, smaller dprimes will result in a lower generalization error, but a higher training error since reducing dprime will reduce M, the number of hypothesis classes. \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
